{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "   id                                            text_en  \\\n0   1  Once again Mr. Costner has dragged out a movie...   \n1   2  This is an example of why the majority of acti...   \n2   3  First of all I hate those moronic rappers, who...   \n3   4  Not even the Beatles could write songs everyon...   \n4   5  Brass pictures movies is not a fitting word fo...   \n\n                                             text_pt sentiment  \n0  Mais uma vez, o Sr. Costner arrumou um filme p...       neg  \n1  Este é um exemplo do motivo pelo qual a maiori...       neg  \n2  Primeiro de tudo eu odeio esses raps imbecis, ...       neg  \n3  Nem mesmo os Beatles puderam escrever músicas ...       neg  \n4  Filmes de fotos de latão não é uma palavra apr...       neg  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text_en</th>\n      <th>text_pt</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Once again Mr. Costner has dragged out a movie...</td>\n      <td>Mais uma vez, o Sr. Costner arrumou um filme p...</td>\n      <td>neg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>This is an example of why the majority of acti...</td>\n      <td>Este é um exemplo do motivo pelo qual a maiori...</td>\n      <td>neg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>First of all I hate those moronic rappers, who...</td>\n      <td>Primeiro de tudo eu odeio esses raps imbecis, ...</td>\n      <td>neg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Not even the Beatles could write songs everyon...</td>\n      <td>Nem mesmo os Beatles puderam escrever músicas ...</td>\n      <td>neg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Brass pictures movies is not a fitting word fo...</td>\n      <td>Filmes de fotos de latão não é uma palavra apr...</td>\n      <td>neg</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('data/imdb-reviews-pt-br.csv', encoding='utf-8')\n",
    "\n",
    "dataset.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "0        neg\n1        neg\n2        neg\n3        neg\n4        neg\n        ... \n49454    pos\n49455    pos\n49456    pos\n49457    pos\n49458    pos\nName: sentiment, Length: 49459, dtype: object"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = dataset['text_pt'].to_numpy()\n",
    "labels = dataset['sentiment']\n",
    "\n",
    "labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/vinicius/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "['mais',\n 'uma',\n 'vez,',\n 'o',\n 'sr.',\n 'costner',\n 'arrumou',\n 'um',\n 'filme',\n 'por',\n 'muito',\n 'mais',\n 'tempo',\n 'do',\n 'que',\n 'o',\n 'necessário.',\n 'além',\n 'das',\n 'terríveis',\n 'seqüências',\n 'de',\n 'resgate',\n 'no',\n 'mar,',\n 'das',\n 'quais',\n 'há',\n 'muito',\n 'poucas,',\n 'eu',\n 'simplesmente',\n 'não',\n 'me',\n 'importei',\n 'com',\n 'nenhum',\n 'dos',\n 'personagens.',\n 'a',\n 'maioria',\n 'de',\n 'nós',\n 'tem',\n 'fantasmas',\n 'no',\n 'armário,',\n 'e',\n 'o',\n 'personagem',\n 'costers',\n 'é',\n 'realizado',\n 'logo',\n 'no',\n 'início,',\n 'e',\n 'depois',\n 'esquecido',\n 'até',\n 'muito',\n 'mais',\n 'tarde,',\n 'quando',\n 'eu',\n 'não',\n 'me',\n 'importava.',\n 'o',\n 'personagem',\n 'com',\n 'o',\n 'qual',\n 'deveríamos',\n 'nos',\n 'importar',\n 'é',\n 'muito',\n 'arrogante',\n 'e',\n 'superconfiante,',\n 'ashton',\n 'kutcher.',\n 'o',\n 'problema',\n 'é',\n 'que',\n 'ele',\n 'sai',\n 'como',\n 'um',\n 'garoto',\n 'que',\n 'pensa',\n 'que',\n 'é',\n 'melhor',\n 'do',\n 'que',\n 'qualquer',\n 'outra',\n 'pessoa',\n 'ao',\n 'seu',\n 'redor',\n 'e',\n 'não',\n 'mostra',\n 'sinais',\n 'de',\n 'um',\n 'armário',\n 'desordenado.',\n 'seu',\n 'único',\n 'obstáculo',\n 'parece',\n 'estar',\n 'vencendo',\n 'costner.',\n 'finalmente,',\n 'quando',\n 'estamos',\n 'bem',\n 'além',\n 'do',\n 'meio',\n 'do',\n 'caminho,',\n 'costner',\n 'nos',\n 'conta',\n 'sobre',\n 'os',\n 'fantasmas',\n 'dos',\n 'kutchers.',\n 'somos',\n 'informados',\n 'de',\n 'por',\n 'que',\n 'kutcher',\n 'é',\n 'levado',\n 'a',\n 'ser',\n 'o',\n 'melhor',\n 'sem',\n 'pressentimentos',\n 'ou',\n 'presságios',\n 'anteriores.',\n 'nenhuma',\n 'mágica',\n 'aqui,',\n 'era',\n 'tudo',\n 'que',\n 'eu',\n 'podia',\n 'fazer',\n 'para',\n 'não',\n 'desligar',\n 'uma',\n 'hora.',\n 'este',\n 'é',\n 'um',\n 'exemplo',\n 'do',\n 'motivo',\n 'pelo',\n 'qual',\n 'a',\n 'maioria',\n 'dos',\n 'filmes',\n 'de',\n 'ação',\n 'são',\n 'os',\n 'mesmos.',\n 'genérico',\n 'e',\n 'chato,',\n 'não',\n 'há',\n 'nada',\n 'que',\n 'valha',\n 'a',\n 'pena',\n 'assistir',\n 'aqui.',\n 'um',\n 'completo',\n 'desperdício',\n 'dos',\n 'talentos',\n 'de',\n 'ice-t',\n 'e',\n 'cubo',\n 'de',\n 'gelo',\n 'que',\n 'foram',\n 'mal',\n 'aproveitados,',\n 'cada',\n 'um',\n 'comprovando',\n 'que',\n 'são',\n 'capazes',\n 'de',\n 'atuar',\n 'e',\n 'agir',\n 'bem.',\n 'não',\n 'se',\n 'incomode',\n 'com',\n 'este,',\n 'vá',\n 'ver',\n 'new',\n 'jack',\n 'city,',\n 'ricochet',\n 'ou',\n 'assistir',\n 'new',\n 'york',\n 'undercover',\n 'para',\n 'ice-t,',\n 'ou',\n 'boyz',\n 'no',\n 'hood,',\n 'higher',\n 'learning',\n 'ou',\n 'friday',\n 'for',\n 'ice',\n 'cube',\n 'e',\n 'ver',\n 'o',\n 'negócio',\n 'real.',\n 'ice-ts',\n 'horrivelmente',\n 'clichê',\n 'diálogo',\n 'sozinho',\n 'faz',\n 'este',\n 'filme',\n 'ralar',\n 'os',\n 'dentes,',\n 'e',\n 'eu',\n 'ainda',\n 'estou',\n 'me',\n 'perguntando',\n 'o',\n 'que',\n 'diabos',\n 'bill',\n 'paxton',\n 'estava',\n 'fazendo',\n 'neste',\n 'filme?',\n 'e',\n 'por',\n 'que',\n 'diabos',\n 'ele',\n 'sempre',\n 'interpreta',\n 'exatamente',\n 'o',\n 'mesmo',\n 'personagem?',\n 'dos',\n 'extraterrestres',\n 'em',\n 'diante,',\n 'todos',\n 'os',\n 'filmes',\n 'que',\n 'eu',\n 'vi',\n 'com',\n 'bill',\n 'paxton',\n 'o',\n 'fizeram',\n 'interpretar',\n 'exatamente',\n 'o',\n 'mesmo',\n 'personagem',\n 'irritante,',\n 'e',\n 'pelo',\n 'menos',\n 'em',\n 'aliens',\n 'seu',\n 'personagem',\n 'morreu,',\n 'o',\n 'que',\n 'o',\n 'tornou',\n 'um',\n 'pouco',\n 'gratificante',\n '...',\n 'no',\n 'geral,',\n 'esse',\n 'é',\n 'lixo',\n 'de',\n 'ação',\n 'de',\n 'segunda',\n 'classe.',\n 'existem',\n 'incontáveis',\n '\\u200b\\u200bfilmes',\n 'melhores',\n 'para',\n 'ver,',\n 'e',\n 'se',\n 'você',\n 'realmente',\n 'quiser',\n 'ver',\n 'esse',\n 'filme,',\n 'assista',\n 'a',\n 'judgment',\n 'night,',\n 'que',\n 'é',\n 'praticamente',\n 'uma',\n 'cópia',\n 'carbono,',\n 'mas',\n 'tem',\n 'melhor',\n 'atuação',\n 'e',\n 'um',\n 'roteiro',\n 'melhor.',\n 'a',\n 'única',\n 'coisa',\n 'que',\n 'fez',\n 'isso',\n 'valer',\n 'a',\n 'pena',\n 'assistir',\n 'foi',\n 'uma',\n 'mão',\n 'decente',\n 'na',\n 'câmera',\n '-',\n 'a',\n 'cinematografia',\n 'era',\n 'quase',\n 'refrescante,',\n 'o',\n 'que',\n 'chega',\n 'perto',\n 'de',\n 'compensar',\n 'o',\n 'horrível',\n 'filme',\n 'em',\n 'si',\n '-',\n 'mas',\n 'não',\n 'é',\n 'bem',\n 'assim.',\n '4/10',\n 'primeiro',\n 'de',\n 'tudo',\n 'eu',\n 'odeio',\n 'esses',\n 'raps',\n 'imbecis,',\n 'que',\n 'não',\n 'poderiam',\n 'agir',\n 'se',\n 'tivessem',\n 'uma',\n 'arma',\n 'pressionada',\n 'contra',\n 'suas',\n 'testas.',\n 'tudo',\n 'o',\n 'que',\n 'eles',\n 'fazem',\n 'é',\n 'amaldiçoar',\n 'e',\n 'atirar',\n 'um',\n 'no',\n 'outro',\n 'e',\n 'agir',\n 'como',\n 'uma',\n 'versão',\n 'clichê',\n 'de',\n 'gangsters.',\n 'o',\n 'filme',\n 'não',\n 'leva',\n 'mais',\n 'de',\n 'cinco',\n 'minutos',\n 'para',\n 'explicar',\n 'o',\n 'que',\n 'está',\n 'acontecendo',\n 'antes',\n 'que',\n 'já',\n 'estivessem',\n 'no',\n 'armazém.',\n 'não',\n 'há',\n 'um',\n 'único',\n 'personagem',\n 'simpático',\n 'nesse',\n 'filme,',\n 'com',\n 'exceção',\n 'do',\n 'sem-teto,',\n 'que',\n 'também',\n 'é',\n 'o',\n 'único',\n 'com',\n 'metade',\n 'do',\n 'cérebro.',\n 'william',\n 'paxton',\n 'e',\n 'william',\n 'sadler',\n 'são',\n 'ambos',\n '\"hill',\n 'billies\"',\n 'e',\n 'sadler',\n 'é',\n 'tão',\n 'vilão',\n 'quanto',\n 'os',\n 'gângsteres.',\n 'eu',\n 'não',\n 'gostava',\n 'dele',\n 'desde',\n 'o',\n 'começo.',\n 'o',\n 'filme',\n 'está',\n 'cheio',\n 'de',\n 'violência',\n 'sem',\n 'sentido',\n 'e',\n 'especialidade',\n 'de',\n 'walter',\n 'hills:',\n 'pessoas',\n 'caindo',\n 'de',\n 'janelas',\n 'com',\n 'vidros',\n 'voando',\n 'por',\n 'toda',\n 'parte.',\n 'não',\n 'há',\n 'praticamente',\n 'nenhum',\n 'enredo',\n 'e',\n 'é',\n 'um',\n 'grande',\n 'problema',\n 'quando',\n 'você',\n 'torce',\n 'por',\n 'ninguém.',\n 'todo',\n 'mundo',\n 'morre,',\n 'exceto',\n 'paxton',\n 'e',\n 'o',\n 'sem-teto',\n 'e',\n 'todos',\n 'recebem',\n 'o',\n 'que',\n 'merecem.',\n 'os',\n 'dois',\n 'únicos',\n 'negros',\n 'que',\n 'podem',\n 'atuar',\n 'são',\n 'o',\n 'sem-teto',\n 'e',\n 'o',\n 'viciado,',\n 'mas',\n 'são',\n 'atores',\n 'de',\n 'profissão,',\n 'não',\n 'irritantes',\n 'rappers',\n 'feios.',\n 'fique',\n 'longe',\n 'dessa',\n 'porcaria.',\n 'e',\n 'observe',\n '48',\n 'horas',\n '1',\n 'e',\n '2',\n 'em',\n 'vez',\n 'disso.',\n 'no',\n 'mínimo,',\n 'eles',\n 'têm',\n 'personagens',\n 'de',\n 'que',\n 'você',\n 'gosta,',\n 'senso',\n 'de',\n 'humor',\n 'e',\n 'nada',\n 'além',\n 'de',\n 'atores',\n 'reais',\n 'no',\n 'elenco.',\n 'nem',\n 'mesmo',\n 'os',\n 'beatles',\n 'puderam',\n 'escrever',\n 'músicas',\n 'que',\n 'todos',\n 'gostassem,',\n 'e',\n 'embora',\n 'walter',\n 'hill',\n 'não',\n 'seja',\n 'um',\n 'mop-top,',\n 'ele',\n 'é',\n 'incomparável',\n 'quando',\n 'se',\n 'trata',\n 'de',\n 'filmes',\n 'de',\n 'ação',\n 'instigantes.',\n 'os',\n 'anos',\n 'noventa',\n 'chegaram',\n 'e',\n 'as',\n 'plataformas',\n 'sociais',\n 'estavam',\n 'mudando',\n 'em',\n 'música',\n 'e',\n 'cinema,',\n 'o',\n 'surgimento',\n 'da',\n 'estrela',\n 'de',\n 'cinema',\n 'do',\n 'rapper',\n 'estava',\n 'em',\n 'pleno',\n 'andamento,',\n 'a',\n 'atuação',\n 'ficou',\n 'em',\n 'segundo',\n 'plano',\n 'para',\n 'cada',\n 'homem',\n 'dominar',\n 'o',\n 'sotaque',\n 'regional',\n 'e',\n 'a',\n 'atuação',\n 'transparente.',\n 'este',\n 'foi',\n 'um',\n 'dos',\n 'muitos',\n 'filmes',\n 'de',\n 'ice-t',\n 'que',\n 'eu',\n 'vi',\n 'quando',\n 'criança',\n 'e',\n 'amei,',\n 'só',\n 'para',\n 'assisti-los',\n 'mais',\n 'tarde',\n 'e',\n 'me',\n 'encolher.',\n 'bill',\n 'paxton',\n 'e',\n 'william',\n 'sadler',\n 'são',\n 'bombeiros',\n 'com',\n 'vidas',\n 'básicas',\n 'até',\n 'que',\n 'um',\n 'inquilino',\n 'em',\n 'chamas',\n 'prestes',\n 'a',\n 'pegar',\n 'fogo',\n 'com',\n 'um',\n 'mapa',\n 'com',\n 'implicações',\n 'douradas.',\n 'eu',\n 'entrego',\n 'a',\n 'walter',\n 'para',\n 'rapidamente',\n 'e',\n 'ordenadamente',\n 'configurar',\n 'os',\n 'personagens',\n 'principais',\n 'e',\n 'localização.',\n 'mas',\n 'eu',\n 'culpo',\n 'todos',\n 'os',\n 'envolvidos',\n 'por',\n 'produzir',\n 'performances',\n 'do',\n 'lame-o.',\n 'o',\n 'gelo',\n 'e',\n 'o',\n 'cubo',\n 'devem',\n 'ter',\n 'ficado',\n 'muito',\n 'quentes',\n 'neste',\n 'momento,',\n 'e',\n 'embora',\n 'eu',\n 'tenha',\n 'gostado',\n 'de',\n 'suas',\n 'carreiras',\n 'como',\n 'rappers,',\n 'na',\n 'minha',\n 'opinião,',\n 'eles',\n 'ficaram',\n 'insatisfeitos',\n 'com',\n 'esse',\n 'filme.',\n 'são',\n 'cerca',\n 'de',\n 'noventa',\n 'minutos',\n 'de',\n 'um',\n 'cara',\n 'ridiculamente',\n 'virando',\n 'as',\n 'costas',\n 'para',\n 'o',\n 'outro',\n 'cara',\n 'até',\n 'o',\n 'ponto',\n 'em',\n 'que',\n 'você',\n 'se',\n 'encontra',\n 'bloqueado',\n 'em',\n 'múltiplos',\n 'estados',\n 'de',\n 'descrença.',\n 'agora',\n 'este',\n 'é',\n 'um',\n 'filme,',\n 'não',\n 'é',\n 'um',\n 'documentário,',\n 'então',\n 'eu',\n 'não',\n 'vou',\n 'perder',\n 'meu',\n 'tempo',\n 'recontando',\n 'todas',\n 'as',\n 'reviravoltas',\n 'estúpidas',\n 'neste',\n 'filme,',\n 'mas',\n 'havia',\n 'muitos,',\n 'e',\n 'eles',\n 'não',\n 'levaram',\n 'a',\n 'lugar',\n 'nenhum.',\n 'eu',\n 'tenho',\n 'a',\n 'sensação',\n 'de',\n 'ver',\n 'isso',\n 'que',\n 'todo',\n 'mundo',\n 'no',\n 'set',\n 'era',\n 'sordeto',\n 'de',\n 'confuso',\n 'e',\n 'apenas',\n 'jogando',\n 'as',\n 'coisas',\n 'fora',\n 'do',\n 'punho.',\n 'há',\n 'duas',\n 'coisas',\n 'que',\n 'eu',\n 'ainda',\n 'gosto,',\n 'uma',\n 'envolve',\n 'uma',\n 'cena',\n 'com',\n 'uma',\n 'agulha',\n 'e',\n 'a',\n 'outra',\n 'é',\n 'uma',\n 'enorme',\n 'pistola',\n '45',\n 'sadlers.',\n 'bottom',\n 'line',\n 'este',\n 'filme',\n 'é',\n 'como',\n 'pizza',\n 'de',\n 'dominó.',\n 'sim,',\n 'eu',\n 'comeria',\n 'se',\n 'estivesse',\n 'com',\n 'fome',\n 'e',\n 'eu',\n 'não',\n 'estivesse',\n 'com',\n 'vontade',\n 'de',\n 'cozinhar,',\n 'mas',\n 'eu',\n 'estou',\n 'bem',\n 'ciente',\n 'que',\n 'tem',\n 'gosto',\n 'de',\n 'porcaria.',\n '3',\n 'estrelas,',\n 'meh.',\n 'filmes',\n 'de',\n 'fotos',\n 'de',\n 'latão',\n 'não',\n 'é',\n 'uma',\n 'palavra',\n 'apropriada',\n 'para',\n 'eles,',\n 'na',\n 'verdade,',\n 'são',\n 'um',\n 'tanto',\n 'ousados.',\n 'suas',\n 'qualidades',\n 'visuais',\n 'atraentes',\n 'são',\n 'reminiscentes',\n 'de',\n 'comerciais',\n 'de',\n 'tv',\n 'caros',\n 'de',\n 'alta',\n 'classe.',\n 'mas,',\n 'infelizmente,',\n 'as',\n 'imagens',\n 'de',\n 'brass',\n 'são',\n 'longas-metragens',\n 'com',\n 'o',\n 'pretexto',\n 'de',\n 'querer',\n 'entreter',\n 'os',\n 'telespectadores',\n 'durante',\n 'mais',\n ...]"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = list()\n",
    "for review in reviews:\n",
    "    review_split = review.split(' ')\n",
    "    for word in review_split:\n",
    "        word = word.lower()\n",
    "        words.append(word)\n",
    "words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "count_words = Counter(words)\n",
    "\n",
    "total_words = len(words)\n",
    "\n",
    "sorted_words=count_words.most_common(total_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "vocab_to_int={w:i+1 for i,(w,c) in enumerate(sorted_words)}\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "encoded_reviews = list()\n",
    "\n",
    "for review in reviews:\n",
    "    encoded_review = list()\n",
    "    for word in review.split():\n",
    "        if word not in vocab_to_int.keys():\n",
    "            encoded_review.append(0)\n",
    "        else:\n",
    "            encoded_review.append(vocab_to_int[word])\n",
    "    encoded_reviews.append(encoded_review)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[  0,   0,   0, ...,   0,   0,   0],\n       [  0,   0,   0, ...,   0,   0,   0],\n       [  0,   0,   0, ...,   0,   0,   0],\n       ...,\n       [  0,   0,   0, ...,   0,   0,   0],\n       [  0,   0,   0, ...,   0,   0,   0],\n       [  0,   0,   0, ...,   5, 611,   1]])"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_length = 256\n",
    "\n",
    "features = np.zeros((len(encoded_reviews), sequence_length), dtype=int)\n",
    "\n",
    "\n",
    "for i, review in enumerate(encoded_reviews):\n",
    "  review_len=len(review)\n",
    "  if review_len <= sequence_length:\n",
    "    zeros=list(np.zeros(sequence_length-review_len))\n",
    "    new=zeros+review\n",
    "  else:\n",
    "    new=review[:sequence_length]\n",
    "features[ i ,:] = np.array( new)\n",
    "\n",
    "features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores positivos: \n",
      "24694\n",
      "Valores negativos: \n",
      "24765\n",
      "Balanceamento do dataset: \n",
      "99.71330506763577\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "labels_encoded = list()\n",
    "positive_counts = 0\n",
    "negative_counts = 0\n",
    "for label in labels:\n",
    "    if label == 'pos':\n",
    "        labels_encoded.append(1.)\n",
    "        positive_counts += 1\n",
    "    else:\n",
    "        labels_encoded.append(0.)\n",
    "        negative_counts += 1\n",
    "labels_encoded = np.array(labels_encoded)\n",
    "print('Valores positivos: ')\n",
    "print(positive_counts)\n",
    "print('Valores negativos: ')\n",
    "print(negative_counts)\n",
    "print('Balanceamento do dataset: ')\n",
    "print((positive_counts / negative_counts) * 100)\n",
    "\n",
    "print(type(labels_encoded))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39567 4946 4946 <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#split_dataset into 80% training , 10% test and 10% Validation Dataset\n",
    "train_x=features[:int(0.8*len(features))]\n",
    "train_y=labels_encoded[:int(0.8*len(features))]\n",
    "valid_x=features[int(0.8*len(features)):int(0.9*len(features))]\n",
    "valid_y=labels_encoded[int(0.8*len(features)):int(0.9*len(features))]\n",
    "test_x=features[int(0.9*len(features)):]\n",
    "test_y=labels_encoded[int(0.9*len(features)):]\n",
    "print(len(train_y), len(valid_y), len(test_y), type(train_y))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "#create Tensor Dataset\n",
    "train_data=TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "valid_data=TensorDataset(torch.from_numpy(valid_x), torch.from_numpy(valid_y))\n",
    "test_data=TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
    "\n",
    "#dataloader\n",
    "batch_size=50\n",
    "train_loader=DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "valid_loader=DataLoader(valid_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader=DataLoader(test_data, batch_size=batch_size, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size:  torch.Size([50, 256])\n",
      "Sample input: \n",
      " tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]])\n",
      "\n",
      "Sample label size:  torch.Size([50])\n",
      "Sample label: \n",
      " tensor([0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1.],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = dataiter.next()\n",
    "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
    "print('Sample input: \\n', sample_x)\n",
    "print()\n",
    "print('Sample label size: ', sample_y.size()) # batch_size\n",
    "print('Sample label: \\n', sample_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SentimentalAnalytics(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
    "        super().__init__()\n",
    "        self.output_size = vocab_size\n",
    "        self.n_layers=n_layers\n",
    "        self.hidden_dim=hidden_dim\n",
    "\n",
    "        #Embedding and LSTM layers\n",
    "        self.embedding=nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm=nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True)\n",
    "\n",
    "        #dropout layer\n",
    "        self.dropout=nn.Dropout(0.3)\n",
    "\n",
    "        #Linear and sigmoid layer\n",
    "        self.fc1=nn.Linear(hidden_dim, 64)\n",
    "        self.fc2=nn.Linear(64, 16)\n",
    "        self.fc3=nn.Linear(16,output_size)\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "            \"\"\"\n",
    "            Perform a forward pass of our model on some input and hidden state.\n",
    "            \"\"\"\n",
    "            batch_size=x.size()\n",
    "\n",
    "            #Embadding and LSTM output\n",
    "            embedd=self.embedding(x)\n",
    "            lstm_out, hidden=self.lstm(embedd, hidden)\n",
    "\n",
    "            #stack up the lstm output\n",
    "            lstm_out=lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "\n",
    "            #dropout and fully connected layers\n",
    "            out=self.dropout(lstm_out)\n",
    "            out=self.fc1(out)\n",
    "            out=self.dropout(out)\n",
    "            out=self.fc2(out)\n",
    "            out=self.dropout(out)\n",
    "            out=self.fc3(out)\n",
    "            sig_out=self.sigmoid(out)\n",
    "\n",
    "            sig_out=sig_out.view(batch_size, -1)\n",
    "            sig_out=sig_out[:, -1]\n",
    "\n",
    "            return sig_out, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        \"\"\"Initialize Hidden STATE\"\"\"\n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        train_on_gpu = torch.cuda.is_available()\n",
    "        if train_on_gpu:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "\n",
    "        return hidden"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentalAnalytics(\n",
      "  (embedding): Embedding(312125, 400)\n",
      "  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=256, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=16, bias=True)\n",
      "  (fc3): Linear(in_features=16, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model w/ hyperparams\n",
    "vocab_size = len(vocab_to_int)+1 # +1 for the 0 padding\n",
    "output_size = 1\n",
    "embedding_dim = 400\n",
    "hidden_dim = 256\n",
    "n_layers = 2\n",
    "\n",
    "net = SentimentalAnalytics(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
    "print(net)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-96-3aa7d282bdcd>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     59\u001B[0m                 \u001B[0mval_h\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtuple\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0meach\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0meach\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mval_h\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     60\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 61\u001B[0;31m                 \u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabels\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     62\u001B[0m                 \u001B[0moutput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mval_h\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnet\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mval_h\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     63\u001B[0m                 \u001B[0mval_loss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcriterion\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutput\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msqueeze\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfloat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/kdp/pos-ia/lib/python3.8/site-packages/torch/cuda/__init__.py\u001B[0m in \u001B[0;36m_lazy_init\u001B[0;34m()\u001B[0m\n\u001B[1;32m    147\u001B[0m             raise RuntimeError(\n\u001B[1;32m    148\u001B[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001B[0;32m--> 149\u001B[0;31m         \u001B[0m_check_driver\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    150\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0m_cudart\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    151\u001B[0m             raise AssertionError(\n",
      "\u001B[0;32m~/kdp/pos-ia/lib/python3.8/site-packages/torch/cuda/__init__.py\u001B[0m in \u001B[0;36m_check_driver\u001B[0;34m()\u001B[0m\n\u001B[1;32m     45\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0m_check_driver\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     46\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_C\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'_cuda_isDriverSufficient'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 47\u001B[0;31m         \u001B[0;32mraise\u001B[0m \u001B[0mAssertionError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Torch not compiled with CUDA enabled\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     48\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_C\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_cuda_isDriverSufficient\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     49\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_C\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_cuda_getDriverVersion\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAssertionError\u001B[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "epochs = 3\n",
    "\n",
    "counter = 0\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "print_every = 100\n",
    "clip=5 # gradient clipping\n",
    "\n",
    "# move model to GPU, if available\n",
    "if train_on_gpu:\n",
    "    net.cuda()\n",
    "\n",
    "net.train()\n",
    "# train for some number of epochs\n",
    "for e in range(epochs):\n",
    "    # initialize hidden state\n",
    "    h = net.init_hidden(50)\n",
    "\n",
    "    # batch loop\n",
    "    for inputs, labels in train_loader:\n",
    "        counter += 1\n",
    "\n",
    "        if(train_on_gpu):\n",
    "            inputs=inputs.cuda()\n",
    "            labels=labels.cuda()\n",
    "        # Creating new variables for the hidden state, otherwise\n",
    "        # we'd backprop through the entire training history\n",
    "        h = tuple([each.data for each in h])\n",
    "\n",
    "        # zero accumulated gradients\n",
    "        net.zero_grad()\n",
    "\n",
    "        # get the output from the model\n",
    "        output, h = net(inputs, h)\n",
    "\n",
    "        # calculate the loss and perform backprop\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        # loss stats\n",
    "        if counter % print_every == 0:\n",
    "            # Get validation loss\n",
    "            val_h = net.init_hidden(50)\n",
    "            val_losses = []\n",
    "            net.eval()\n",
    "            for inputs, labels in valid_loader:\n",
    "\n",
    "                # Creating new variables for the hidden state, otherwise\n",
    "                # we'd backprop through the entire training history\n",
    "                val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "                output, val_h = net(inputs, val_h)\n",
    "                val_loss = criterion(output.squeeze(), labels.float())\n",
    "\n",
    "                val_losses.append(val_loss.item())\n",
    "\n",
    "            net.train()\n",
    "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}